# Project's implementation process: 

## Task: 

| Task                       |   Content                                                                                                  | Assign |
|:--------------------------:|:----------------------------------------------------------------------------------------------------------:|:-----: |
| Task 1: Crawl Data         |  Using crawl data tool like (Selenium, scrapy,...) or methods like requests to crawl data from Shopee      | Thinh, Hoai  |
| Task 2: Automatic process data      | Using AirFlow to automatically crawl data                                                         | Thinh  |
| Task 3: Store Data         |  Using data management system to store data like MongoDB                                                   | Thinh, Luu    |
| Task 4: Preprocess Data    |  Using file Python                                                                                         |  Quan, Luu |
| Task 5: Analyze data       | Build basic model to analyze some problems                                                                 |   All      |
| Task 6: Visuallize Data    |  Using PowerBI                                                                                             | Quan, Hoai |

## Note: 
1. 2-3 days, each candidate pushes commit about their processing of them in these day.

2. If not doing anything, you will write not doing.

3. Time start: 16/10/2023
## Thinh's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 11/10/2023  | Task 1: Crawl Data         |  Using Selenium to crawl data: Crawl multiple pages and crawl basic title, link, default price, discount price of each items   | Processing/Avoid detecting bot     |       3h      |
| 16/10/2023  | Not doing       |  Busy in deadline |  Not doing     |       0h      |
| 17/10/2023  | Not doing         |  Busy in deadline    |  Not doing     |      0h    |
| 18/10/2023  | Not doing        |  Busy in deadline    |  Not doing     |       0h      |
| 19/10/2023  | Task 1: Crawl Data        |  Using threads to crawl multiprocessing => Improve crawl speed  |  Implementing     |       2h30      |
| 20/10/2023  | Not doing        |  Busy in deadline    |  Not doing     |       0h      |
| 21/10/2023  | Not doing        |  Lazy :)))   |  Not doing     |       0h      |
| 22/10/2023  | Task 1: Crawl Data         |  Write sequential code to crawl data   |  Because threading met a lot of trouble     |       3h30      |
| 23/10/2023  | Not doing        |  Lazy :)))   |  Not doing     |       0h      |
| 24/10/2023  | Task 1: Crawl Data        |  Finish basic one shop  |  Need to be edited more    |       5h      |


## Quan's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 16/10/2023| Task 3 Preprocess data| Using jupiter| No| No|
| 24/10/2023| Task 5 Analyze data | Raise problems that need to be solved in data analysis| Done| 1h|


## Hoai's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 12/10/2023  | Task 1: Crawl Data         | Try using Scrapy Selenium to crawl   | This library is out of date, get error while run     |       1h      |
| 13/10/2023  | Task 1: Crawl Data         | Using API    |With Shoppe, the platform block users from accessing the API. Sendo and Tiki allow it     |       1h      |
| 14/10/2023  | Task 1: Crawl Data         | Using Scrapy Splash    | Can use this library to crawl web rendered from javascript     |       1h      |
| 23/10/2023  | Task 1: Crawl Data         | Crawl lazada    | Test basic request      |       1h      |
| 24/10/2023  | Task 1: Crawl Data         | Implement crawl on many shope    | Send many request -> meet capcha      |       1h      |
| 14/10/2023  |     Task 1: Crawl Data     | Finish crawl shop info    | ok   |       1h      |


## Luu's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 12/10/2023  | Task 1: Crawl Data         |  Using Browsermob Proxy to get HAR file   | Proxy connection failed     |       0h      |
| 23/10/2023  | Not doing         |     |      |       0h      |
| 24/10/2023  | Not doing         |     |      |       0h      |
| 25/10/2023  | Not doing         |     |      |       0h      |


## Son's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|

