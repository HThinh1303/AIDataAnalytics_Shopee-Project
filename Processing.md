# Project's implementation process: 

## Task: 

| Task                       |   Content                                                                                                  | Assign |
|:--------------------------:|:----------------------------------------------------------------------------------------------------------:|:-----: |
| Task 1: Crawl Data         |  Using crawl data tool like (Selenium, scrapy,...) or methods like requests to crawl data from Shopee      | Thinh, Hoai  |
| Task 2: Automatic process data      | Using AirFlow to automatically crawl data                                                         | Thinh  |
| Task 3: Store Data         |  Using data management system to store data like MongoDB                                                   | Thinh, Luu    |
| Task 4: Preprocess Data    |  Using file Python                                                                                         |  Quan, Luu |
| Task 5: Analyze data       | Build basic model to analyze some problems                                                                 |   All      |
| Task 6: Visuallize Data    |  Using PowerBI                                                                                             | Quan, Hoai |

## Note: 
1. 2-3 days, each candidate pushes commit about their processing of them in these day.

2. If not doing anything, you will write not doing.
## Thinh's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 11/10/2023  | Task 1: Crawl Data         |  Using Selenium to crawl data: Crawl multiple pages and crawl basic title, link, default price, discount price of each items   | Processing/Avoid detecting bot     |       3h      |

## Quan's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|


## Hoai's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 12/10/2023  | Task 1: Crawl Data         | Try using Scrapy Selenium to crawl   | This library is out of date, get error while run     |       1h      |
| 13/10/2023  | Task 1: Crawl Data         | Using API    |With Shoppe, the platform block users from accessing the API. Sendo and Tiki allow it     |       1h      |
| 14/10/2023  | Task 1: Crawl Data         | Using Scrapy Splash    | Can use this library to crawl web rendered from javascript     |       1h      |


## Luu's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 12/10/2023  | Task 1: Crawl Data         |  Using Browsermob Proxy to get HAR file   | Proxy connection failed     |       0h      |


## Son's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|

