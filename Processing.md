# Project's implementation process: 

## Task: 

| Task                       |   Content                                                                                                  | Assign |
|:--------------------------:|:----------------------------------------------------------------------------------------------------------:|:-----: |
| Task 1: Crawl Data         |  Using crawl data tool like (Selenium, scrapy,...) or methods like requests to crawl data from Shopee      | Thinh, Hoai  |
| Task 2: Automatic process data      | Using AirFlow to automatically crawl data                                                         | Thinh  |
| Task 3: Store Data         |  Using data management system to store data like MongoDB                                                   | Thinh, Luu    |
| Task 4: Preprocess Data    |  Using file Python                                                                                         |  Quan, Luu |
| Task 5: Analyze data       | Build basic model to analyze some problems                                                                 |   All      |
| Task 6: Visuallize Data    |  Using PowerBI                                                                                             | Quan, Hoai |

## Note: 
1. 2-3 days, each candidate pushes commit about their processing of them in these day.

2. If not doing anything, you will write not doing.

3. Time start: 16/10/2023
## Thinh's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 11/10/2023  | Task 1: Crawl Data         |  Using Selenium to crawl data: Crawl multiple pages and crawl basic title, link, default price, discount price of each items   | Processing/Avoid detecting bot     |       3h      |
| 16/10/2023  | Not doing       |  Busy in deadline |  Not doing     |       0h      |
| 17/10/2023  | Not doing         |  Busy in deadline    |  Not doing     |      0h    |
| 18/10/2023  | Not doing        |  Busy in deadline    |  Not doing     |       0h      |
| 19/10/2023  | Task 1: Crawl Data        |  Using threads to crawl multiprocessing => Improve crawl speed  |  Implementing     |       2h30      |
| 20/10/2023  | Not doing        |  Busy in deadline    |  Not doing     |       0h      |
| 21/10/2023  | Not doing        |  Lazy :)))   |  Not doing     |       0h      |
| 22/10/2023  | Task 1: Crawl Data         |  Write sequential code to crawl data   |  Because threading met a lot of trouble     |       3h30      |
| 23/10/2023  | Not doing        |  Lazy :)))   |  Not doing     |       0h      |
| 24/10/2023  | Task 1: Crawl Data        |  Finish basic one shop  |  Need to be edited more    |       5h      |
| 25/10/2023  | Not doing        |  Lazy :)))   |  Not doing     |       0h      |
| 26/10/2023  | Task 1: Crawl Data       |  Test code to crawl data   |   Need to be edited more    |       30      |
| 27/10/2023  | Task 1: Crawl Data       |  Test code to crawl data   |   Need to be edited more    |       2h30      |
| 28/10/2023  | Not doing        |  Lazy :)))   |  Not doing     |       0h      |
| 29/10/2023  | Task 1: Crawl Data, Task 2: Store data       |  Test code to crawl data and store data  |   Need to be edited more   |       1h30    |
| 30/10/2023  | Task 1: Crawl Data, Task 2: Store data         |  Test code to crawl data and store data  |   Need to be edited more   |       3h30    |


## Quan's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 16/10/2023| Task 3 Preprocess data| Using jupiter| No| No|
| 24/10/2023| Task 5 Analyze data | Raise problems that need to be solved in data analysis| Done| 1h|
| 27/10/2023| Not doing | Busy | No working | 0h|
| 30/10/2023| Not doing | Busy | No working | 0h|
|4/11/2024| data processing|Drop columns unnecessary| Done| 2h|
|5/11/2024| data processing| get color columns| Done| 2h|
|18/11/2024| data processing| data is clean| Done| 1h

## Hoai's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 12/10/2023  | Task 1: Crawl Data         | Try using Scrapy Selenium to crawl   | This library is out of date, get error while run     |       1h      |
| 13/10/2023  | Task 1: Crawl Data         | Using API    |With Shoppe, the platform block users from accessing the API. Sendo and Tiki allow it     |       1h      |
| 14/10/2023  | Task 1: Crawl Data         | Using Scrapy Splash    | Can use this library to crawl web rendered from javascript     |       1h      |
| 23/10/2023  | Task 1: Crawl Data         | Crawl lazada    | Test basic request      |       1h      |
| 24/10/2023  | Task 1: Crawl Data         | Implement crawl on many shope    | Send many request -> meet capcha      |       1h      |
| 25/10/2023  |     Task 1: Crawl Data     | Finish crawl shop info    | ok   |       1h      |
| 26/10/2023  |     Task 1: Crawl Data     | Crawl all shope    | Get error beacause capcha   |       1h      |
| 27/10/2023  |     Task 1: Crawl Data     | Fix bug  capcha | Cannot fix   |       1h      |
| 28/10/2023  |     Task 1: Crawl Data     | Fix bug  capcha    | Cannot fix   |       1h      |
| 29/10/2023  |     Not Doing     | Not Doing    | Not Doing   |       0h      |
| 30/10/2023  |     Not Doing     | Not Doing    | Not Doing   |       0h      |




## Luu's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 12/10/2023  | Task 1: Crawl Data         |  Using Browsermob Proxy to get HAR file   | Proxy connection failed     |       0h      |
| 23/10/2023  | Not doing         |     |      |       0h      |
| 24/10/2023  | Not doing         |     |      |       0h      |
| 25/10/2023  | Not doing         |     |      |       0h      |


## Son's Processing

| Date        | Task                       |  Content                       | Status/Trouble                     |Execution time | 
| ------------|:--------------------------:|:------------------------------:|:----------------------------------:|:-------------:|
| 18/10/2023  | Task 1: Crawl Data         | Set up srcapy.spider object   | Fine     |       6h      |
| 19/10/2023  | Task 1: Crawl Data         | Understand thier API    | Aggressive with bot    |       6h      |
| 20/10/2023  | Task 1: Crawl Data         | Solve "bot" problem    | Solved (acceptable level)    |       6h      |
| 21/10/2023  | Task 1: Crawl Data         | Solve "Human spam request"    | Still finding a way to rotate my IP      |       6h      |
| 22/10/2023  | Not doing         |     |      |       0h      |
| 23/10/2023  | Task 1: Crawl Data         | Finishing Selenium object    | Still waiting for an "IP rotation" method   |       6h      |
| 24/10/2023  | Task 1: Crawl Data         | Improvement Selenium object    | Nothing to say   |       4h      |
| 25/10/2023  | Task 1: Crawl Data         | Looking for "IP rotation" method    | No money   |       10h      |
| 26/10/2023  | Not doing         |     |      |       0h      |
